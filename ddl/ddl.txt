next up:
*_functions.sql
FEATURE: postgres exclude constraints
FEATURE: materialized views + triggers + indexes
FEATURE: covering indexes
FEATURE: composite primary keys and foreign keys and unique keys
FEATURE: unique indexes
Try to integrate these into the main schema, rather than in a dummy table.

Also: TYPEs, DOMAINs, ENUMs. aaargh.
I don't need to add these now because the sakila database doesn't use them (I'm
going to strip it out from the postgres schema too). Kick the can down the
road, when the problem is more well-defined.

forget about offering users the options to slot in their own predicates.
WithDB's behavior is fixed, take it or leave it. Instead, offer them a way to
write their own CatalogOption function, leveraging the existing IntrospectQuery
and MapColumns/MapTables/etc if necessary.

omfg both postgres and mysql support functions AND stored procedures, so now
I'd have to figure out how that looks from the user-definition side (in Go
files) and the database-definition side (reading from the db).
ALSO: functions may be user-defined aggregate functions or user-defined window
functions. guh.

ddl.go
column_ddl.go | constraint_ddl.go | index_ddl.go
trigger.go
trigger_ddl.go
function.go
function_ddl.go
table.go
table_ddl.go
view.go
view_ddl.go
v.go | t.go
schema.go
catalog.go
migration_commands.go

if the user eventually wants to expose the sq.Query produced by a DDLView, I
can add a public .Query field to V. Make a new constructor called NewV(dialect
string, view *View, wantColumns []string) to keep the fields private but allow
the user to inject them. Of course all this can be added later, only when
required. I don't have to add it in now.

dont bother with diffing catalogs to migrations at first:
func (c Catalog) GenerateDDL(w io.Writer) error
func (c Catalog) GenerateStructs(w io.Writer) error
GenerateDDL will append commands directly into a MigrationCommands struct,
bypassing the CatalogMigration struct, because we have no need for it.

to clean a database (for example to reset its state to zero), all you have to
do is to loop the gotCatalog Catalog struct, for each table and view and
function you simply convert it to the corresponding
DropTableCommand/DropViewCommand/DropFunctionCommand and append it into the
MigrationCommands struct. You can then either execute the MigrationCommands
directly or write it out to a file, the choice is yours.

v.AsQuery()
v.SQL() // used if you have the view literal
This means the View struct must now store the full view definition, and not
just the select query part. It also means we have to omit the IsMaterialized
part of the struct. Everything compiles down to an SQL string.

automigrate ops:
- add schema
- add table
- add column
- alter column nullable, default
- change index columns
generate migration ops:
- all automigrate ops

trigger_migration.go
function_migration.go
view_migration.go
table_migration.go
schema_migration.go
catalog_migration.go

func MigrateCatalog(gotCatalog, wantCatalog Catalog) (CatalogMigration, error)
func MigrateSchema(gotCatalog Catalog, wantSchema Schema) (SchemaMigration, error)
func MigrateTable(dialect string, gotSchema Schema, wantTable Table) (TableMigration, error)
func MigrateColumn(dialect string, gotTable Table, wantColumn Column) (ColumnMigration, error)

func (c Catalog) MigrateCatalog(wantCatalog Catalog) (CatalogMigration, error)
func (c Catalog) MigrateSchema(wantSchema Schema) (SchemaMigration, error)
func (c Catalog) MigrateTable(wantTable Table) (TableMigration, error)
func (c Catalog) MigrateColumn(wantColumn Column) (ColumnMigration, error)
// the below 2 can detect identity, hence we can generate alter migrations. but
non-online migrations will not be possible.
func (c Catalog) MigrateConstraint(wantConstraint Column) (ConstraintMigration, error)
func (c Catalog) MigrateIndex(wantIndex Index) (IndexMigration, error)
// all the migrations below should be create-only i.e. no alteration is possible
func (c Catalog) MigrateView(wantView View) (ViewMigration, error)
func (c Catalog) MigrateFunction(wantFunction Function) (FunctionMigration, error)
func (c Catalog) MigrateTrigger(wantTrigger Trigger) (TriggerMigration, error)

do we want to implement support for dropping unused tables/columns/constraints/indexes/views/functions/triggers? something like
func (c Catalog) WantCatalog(wantCatalog Catalog) (CatalogMigration, error) will generate the create/alter commands. whereas
func (c Catalog) GotCatalog(gotCatalog Catalog) (CatalogMigration, error) will generate the drop commands.

generating online migrations for functions and views is a huge jar of worms.
because functions can reference other functions and views can reference other
views, it is not sufficient to simply create a new function/view, atomically
rename current to old and new to current, then drop old. Because even if you
rename current to old, there may be other functions that are still referencing
old. You must work out the depedency graph and rebuild all depedencies, which
sucks major ass. Therefore, alteration for functions and views should not be
supported at all.
generating non-online function and view is impossible, because we cannot detect
function/view identity.

generating online migrations for altering indexes is also not possible, but for
different reasons. You cannot build a new index alongside the old index,
because they might not be valid at the same time. For example, the reason for
changing an index might be because a column is removed. So keeping the old
index around may be impossible because a referenced column no longer exists.
basically don't supprt altering indexes as well.
generating non-online index migration is possible, because we can detect index
identity.

triggers can't be altered online safely because two triggers living
side-by-side may result in incorrect behaviour.
generating non-online trigger migrations is also not possible because we cannot
detect trigger identity.

func (m CatalogMigration) Commands() MigrationCommands
type MigrationCommands struct {
	Dialect               string
	SchemaCommands        []Command
	FunctionCommands      []Command
	TableCommands         []Command
	ViewCommands          []Command
	TableFunctionCommands []Command
	TriggerCommands       []Command
	DualWriteTriggers     []Command
	BackfillQueries       []sq.Query
	GhostTableCommands    []Command
	ForeignKeyCommands    []Command
	RenameCommands        []Command
	DropCommands          []Command
}

Idea: MigrateCatalog() should generate all of the drop (unused) X commands as well. AutoMigrate will simply ignore the drop queries.
    but what about the scheduled drop (old <-> new) queries, like for migrating tables in sqlite?
