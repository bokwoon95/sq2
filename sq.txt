sq.go
param.go
fmt.go
predicate.go
rowvalue.go
table_info.go
field_info.go <-> custom_field.go <-> assignment.go
blob_field.go | boolean_field.go | json_field.go | numberfield.go | string_field.go | time_field.go
join_table.go
variadic_query.go
subquery_field.go | cte.go
...
window.go (at very last because nothing depends on it)

BeforeQuery Hook
AfterQuery Hook
Before the query gets run by Fetch/Exec, you have the option to reach in and manipulate that query into one or more queries which are then run one after the other.
This is incredibly powerful for things like audit logging (INSERT into an audit table after any sensitive SELECT/INSERT/UPDATE/DELETE), as well as enforcing an application-wide constraints like for application-level temporal tables.
AfterQuery hook -could- be used to replace the logger hook
More importantly AfterQuery gives you the option to add post-query triggers: queries that are run only if the previous query succeeded. You can use it to validate DB state after running a particular query, and raising an error if so.
By running the AfterQuery Hook with a transaction, it gives you the ability to run one or more arbitrary queries on the database after the initial query and rollback the entire transaction if you wish.

A CompiledQuery[T] Fetch will check if there are any BeforeQuery hooks on the database for the current table, and if there are it will submit the underlying query to that hook (losing all the compiled-ness of the query). But if there are no BeforeQuery hooks, or if the BeforeQuery hooks don't modify the query, then the compiled query's query string can be used as-is.

NOTE: should I change `excludedTableQualifiers []string` to `excludeTableQualifier func(name string) bool`? It affords more filtering power, but at the cost of the param being a complete black box to functions that receive it.

INCOMPATIBILITY.txt
due to the ever-changing nature of database features, some of the semantic stuff we forbid today may become irrelvant tomorrow
- e.g. currently named params are not allowed for postgres and mysql, because they don't support it. There is a small chance that it may eventually be added, but when it does do we undo the behavior? Would that be considered a breaking change?
- I think it's safe to just forbid that stuff today, so that you can be reasonably sure that no one's codebase has that code. Allowing previously-forbidden behavior is then backwards compatible, because no one was coding like that anyway.

TODO: currently for some dialect-specific features I'm just ignoring and moving on e.g. MySQL's OnUpdateCurrentTimestamp is ignored by other dialects. This contrasts to my attitude with other things, like returning an error if the using tries to use RIGHT JOIN or FULL JOIN with SQLite because it isn't supported. So do I ignore non-applicable dialect-specific features, or do I return an error to the user to point it out? Where do I draw the line? I need to take a principled stand on this, preferably in a forwards-compatible way.
Put more succinctly: is there ever a case where the user has to convert a query from one dialect to another in a generic way? What is the context surrounding that? Because if I silently truncate some stuff (like the RETURNING clause), will the query still work fine in that context?
I have decided: try to silently accomodate as much as possible, and do not enforce SQL semantics.

Don't call it NewDB, call it Wrap(Queryer) Queryer. So users will no longer be able to call concrete methods on the DB, basically they can only make it do things through Fetch and Exec.
God but all this interface wrapping and unwrapping, won't it be unperformant though?

All this could be solved if I created a separate struct just to hold sq-specific config like loggers and hooks. The user can provide it if they want or they can just pass nil. The upside is that they can now use *sql.DB, *sql.Tx, *sql.Conn, *sql.Stmt in its full glory without wrapping it in some iffy extension interface.

FetchContext(ctx, db, sq.SQLite.
    From(),
    rowMapper,
)

// how is this better though? The user can still forget to pass in the config struct, causing all the loggers and triggers to go to waste.
// maybe it's just time to embrace the fact that sq triggers will not be reliable enough to enforce database-level constraints, like temporal table filters.
FetchContext(ctx, db, nil, sq.SQLite.
    From(),
    rowMapper,
)
There -is- an alternative way... all Fetch and Exec now take in an *sq.DB, instead of a Queryer.
    The one thing that would make this more palatable is if Fetch and Exec could be re-implemented by external packages i.e. only depedendent on exported functions and types.
    So if you wanted a Fetch that only takes in an *sql.DB you can rewrite it yourself
    ^ yes... I think this is the way

think about removing ToSQL from the Query interface, if it doesn't pull its weight. Will need to write more queries with sq first.

The only downside is if you modify the SELECTed column list before it hits the database, then whatever comes back will most likely cause the rowmapper to panic.

sq README needs a FAQ section, just like how Maddy mail server does. I naturally gravitaed towards the FAQ link in order to learn more about maddy, and was able to learn so much it just from reading the FAQ alone.

row.Close() instead of row.Return() or row.Exit() with runtime.Goexit() shenanigans, because row.Close() can be orthogonal across Fetch, FetchOne and FetchSlice.
That is, instead of terminating the function there and then you simply mark the row iteration as complete and that subsequent row iterations should not occur.

How much slower is checking before quoting an identifier compared to just quoting it? Need to run some benchmarks, decide if it's worth it.

investigate using type assertion and pointers fro performance:
https://www.reddit.com/r/golang/comments/9xs0r2/why_is_type_assertion_so_fast/
"interface asserted to pointer and pointer assigned to interface are both optimized by gc. For other kinds of types other than pointer, the larger size their values, the slower in assertions and assignments."
type assertions will be used very often during query manipulation (inside a trigger, etc). We want query manipulation to be fast.

investigate using type conversion and alias types for perforance:
https://stackoverflow.com/a/32253871
"converting to and from the underlying type of your custom type does not make a copy if it."
type conversions can be used very often for converting between the XXXField types and FieldInfo, which we want to be fast.

In general, will using struct values instead of struct pointers be faster when building a query? I need to know.
